{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the ENIGMA-PD documentation page!","text":"<p>This site provides information on the ENIGMA-PD team, ongoing and completed projects, and useful resources.  </p> <ul> <li> <p> Team</p> <p> People behind enigma-pd</p> </li> <li> <p> Sites</p> <p> Global study populations</p> </li> <li> <p> Resources</p> <p> Current pipelines and resources</p> </li> <li> <p> Ongoing Projects</p> <p> Ongoing Projects</p> </li> <li> <p> Completed Projects</p> <p> Completed Projects</p> </li> </ul>"},{"location":"projects/completed/connectomics/","title":"Connectomics project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/completed/cort_sub/","title":"Cortical-Subcortical project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/completed/overview/","title":"ENIGMA-PD completed projects showcase","text":"<ul> <li> <p> Cortical-Subcortical</p> </li> <li> <p> Subcortical shape</p> </li> <li> <p> Diffusion (TBSS)</p> </li> <li> <p> PySustain</p> </li> <li> <p> Connectomics</p> </li> </ul>"},{"location":"projects/completed/py-sustain/","title":"PySustain project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/completed/shape/","title":"Shape project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/completed/tbss/","title":"Diffusion (tbss) project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/ongoing/cognitive_reserve/","title":"Cognitive reserve (fMRI) project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/ongoing/freesurfer7/","title":"Welcome to the ENIGMA-PD FreeSurfer 7 guidelines!","text":"<p>This page is created to guide collaborating ENIGMA-PD sites through the FreeSurfer processing steps. The outcomes include cortical thickness, cortical surface area, and volume of subcortical regions and their subfields. All steps and code required are combined into the guidelines presented here. If you have any questions, concerns, or issues, please contact the ENIGMA-PD core team at enigma-pd@amsterdamumc.nl. </p>"},{"location":"projects/ongoing/freesurfer7/#leaderboard","title":"Leaderboard","text":"<p>To help motivate and monitor each site's progress, we maintain a leaderboard that outlines all the steps detailed in these guidelines. If you are in charge of data processing at your site, please request access and regularly update your progress on the current steps on the ENIGMA-PD Leaderboard.</p>"},{"location":"projects/ongoing/freesurfer7/#overview","title":"Overview","text":"<p>The figure shows the expected outcomes and corresponding processing steps - most of which can be performed using the Nipoppy framework and helper Python package. We strongly recommend adoption of Nipoppy tools to simplify coordination and ensure reproducibility of this end-to-end process across all sites.  </p>"},{"location":"projects/ongoing/freesurfer7/#setting-up-nipoppy","title":"Setting up Nipoppy","text":"<p>Nipoppy is a lightweight framework for standardized data organization and processing of neuroimaging-clinical datasets. Its goal is to help users adopt the FAIR principles and improve the reproducibility of studies. </p> <p>The ongoing collaboration between the ENIGMA-PD team and Nipoppy team has streamlined data curation, processing, and analysis workflows, which significantly simplifies tracking of data availability, addition of new pipelines and upgrading of existing pipelines. The ENIGMA-PD and Nipoppy team is available to support and guide users through the process of implementing the framework, ensuring a smooth transition. To join the Nipoppy support community, we recommend joining their Discord channel. Here you can ask questions and find answers while working with Nipoppy. </p> <p>Here, primairly we will use Nipoppy to help you with 1) BIDSification, 2) FreeSurfer7 processing, 3) Sub-segmentation and 4) Quality control. </p> <p>For more information, see the Nipoppy documentation.</p>"},{"location":"projects/ongoing/freesurfer7/#getting-started","title":"Getting started","text":"<p>To install Nipoppy, we refer to the Installation page. </p> <p>Once Nipoppy is successfully installed, you will need to create a Nipoppy dataset and populate it with your data. There are a few different starting points depending on the current state of your dataset. If you have your data already in BIDS format, click here. If you have DICOM of NIFTI files that are not yet in BIDS, continue below. If you're not sure what BIDS is or if you're wondering why you should convert your data into BIDS at all, you can find more info here.</p>"},{"location":"projects/ongoing/freesurfer7/#starting-from-source-data-either-dicoms-or-niftis-that-are-not-yet-in-bids","title":"Starting from source data (either DICOMs or NIfTIs that are not yet in BIDS)","text":"<p>This is the scenario assumed by the Nipoppy Quickstart page. Follow this guide to: 1. Create an empty Nipoppy dataset (i.e. directory tree) 2. Write a manifest file representing your data 3. Modify the global config file with paths to e.g., path to your container directory</p> <p>Note: if your dataset is cross-sectional (i.e. only has one session), you still need to create a <code>session_id</code> for the manifest. In this case the value would be the same for all participants.</p> <p>When you reach the end of the Quickstart, it is time to copy and reorganize your raw imaging data to prepare them for BIDS conversion. Once this is done, you can find how to perform the BIDSification within the Nipoppy framework here. We recommend applying a containerized BIDS-conversion pipeline that can be run within Nipoppy. Here you can find how to download containers and here you can find how to run them within Nipoppy.</p>"},{"location":"projects/ongoing/freesurfer7/#starting-with-bidsified-data","title":"Starting with BIDSified data","text":"<p>If your dataset is already in BIDS, then the manifest-generation step can be skipped by initializing the Nipoppy dataset with this command, specifying the path to your new dataset and the path to your existing BIDS data:</p> <pre><code>nipoppy init --dataset &lt;dataset_root&gt; --bids-source &lt;path_to_existing_bids_data&gt;\n</code></pre> <p>This command will create a Nipoppy dataset (i.e. directory tree) from preexisting BIDS dataset and automatically generate a manifest file for you! </p>"},{"location":"projects/ongoing/freesurfer7/#bids-datasets-without-sessions","title":"BIDS datasets without sessions","text":"<p>If the existing BIDS data does not have session-level folders, Nipoppy will create \"dummy sessions\" (called <code>unnamed</code>) in the manifest. This is because the Nipoppy manifest still requires a non-empty <code>session_id</code> value when imaging data is available for a participant.</p> <p>If it is feasible to redo the BIDSification to include session folders, we recommend doing so since this is considered good practice. Otherwise, Nipoppy can still be run, but you will need to make some manual changes. For more information, see here</p>"},{"location":"projects/ongoing/freesurfer7/#starting-from-data-already-processed-with-freesurfer7","title":"Starting from data already processed with FreeSurfer7","text":"<p>We still encourage you to use Nipoppy to organize your source and/or BIDS data with your processed FS7 output to make use of automated trackers and downstream subsegmentation processing. However, you may need to some help depending on your version of FreeSurfer and naming convention of <code>participant_id</code>. Reach out to us on our Discord channel and we would be happy to help! </p>"},{"location":"projects/ongoing/freesurfer7/#running-freesurfer-7","title":"Running FreeSurfer 7","text":"<p>When you reach this point, the hardest part is behind you and we can finally come to the real stuff. We will run FreeSurfer 7 through fMRIPrep using Nipoppy. See here for additional information about running processing pipelines with Nipoppy.</p> <p>We will apply the FreeSurfer functionalities that are included in the fMRIPrep pipeline. We assume here that you have Apptainer installed as your container platform (see here for more info and how to get it). Now, you can pull the fMRIPrep container in the following way:</p> <pre><code>apptainer build fmriprep_24.1.1.sif \\\n                    docker://nipreps/fmriprep:24.1.1\n</code></pre> <p>Make sure that you have the fMRIPrep container stored in the containers folder that you reference to in your global config file.</p> <p>For more information on fMRIPrep, see the fMRIPrep documentation</p>"},{"location":"projects/ongoing/freesurfer7/#setting-up-configuration","title":"Setting up configuration","text":"<p>Next, we will need to install the fMRIPrep pipeline within Nipoppy. You can do this by simply running:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 15427833\n</code></pre> <p>15427833 is the Zenodo ID for the Nipoppy configuration files for fmriprep 24.1.1. Read more about this step here.</p> <p>Once the pipeline is installed, open the global config file and check whether the correct fMRIPrep version is included under <code>PIPELINE_VARIABLES</code>. The following paths should be replaced here under the correct version of the fMRIPrep pipeline in the global config file: - <code>&lt;FREESURFER_LICENSE_FILE&gt;</code> (required to run FreeSurfer; you can get a FreeSurfer licence for free at the FreeSurfer website) - <code>&lt;TEMPLATEFLOW_HOME&gt;</code> (see here for more info on Templateflow)</p>"},{"location":"projects/ongoing/freesurfer7/#run-pipeline","title":"Run pipeline","text":"<p>Finally, simply run the following line of code:</p> <pre><code>nipoppy process --pipeline fmriprep --pipeline-version 24.1.1 --dataset &lt;dataset_root&gt;\n</code></pre> <p>This should initiate the FS7 segmentation of your T1-weighted images! </p> <p>Note: the command above will run all the participants and sessions in a loop, which may be inefficient. If you're using an HPC, you may want to submit a batch job to process all participants/sessions. Nipoppy can help you do this by 1. Generate a list of \"remaining\" participants to be processed for your job-subission script: <code>nipoppy process --pipeline fmriprep --pipeline-version 24.1.1 --dataset &lt;dataset_root&gt; --write-list &lt;path_to_participant_list&gt;</code> 2. Automatically submit HPC jobs for you with additional configuration (more info here)</p>"},{"location":"projects/ongoing/freesurfer7/#track-pipeline-output","title":"Track pipeline output","text":"<p>The <code>nipoppy track-processing</code> command can help keep track of which participants/sessions have all the expected output files for a given processing pipeline. See here for more information. Running this command will update the <code>processing_status.tsv</code> under the <code>derivatives</code> folder.</p>"},{"location":"projects/ongoing/freesurfer7/#extract-pipeline-output","title":"Extract pipeline output","text":"<p>For automatic extraction of the cortical thickness, cortical surface area and subcortical volume into .tsv files, you can use another Nipoppy pipeline, called fs_stats. The Zenodo ID for this pipeline is 15427856, so you can install it with the following command:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 15427856\n</code></pre> <p>Remember to define the freesurfer licens file path in your global config file under the newly installed pipeline. Then, you can simply run </p> <pre><code>nipoppy extract --pipeline fs_stats --dataset &lt;dataset_root&gt;\n</code></pre> <p>to get things going. You can find the extracted data under <code>&lt;dataset_root&gt;/derivatives/freesurfer/7.3.2/idp/</code>.</p> <p>Once FS7 processing and extraction has completed, you can move on to the subsegmentations.</p>"},{"location":"projects/ongoing/freesurfer7/#running-the-freesurfer-subsegmentations","title":"Running the FreeSurfer subsegmentations","text":"<p>\ud83c\udf89 It\u2019s go time! The subsegmentations pipeline is now ready to be run! Since you\u2019ve all just been through fMRIPrep in Nipoppy, this next step will feel familiar as running this pipeline follows a very similar workflow.</p> <p>About the pipeline: This pipeline uses existing FreeSurfer 7 functionalities to extract subnuclei volumes from subcortical regions like the thalamus, hippocampus, brainstem, hypothalamus, amygdala, and hippocampus. It requires completed FreeSurfer output (<code>recon-all</code>) and integrates the subsegmentation outputs directly into the existing <code>/mri</code> and <code>/stats</code> directories. Additionally, the pipeline will perform Sequence Adaptive Multimodal SEGmentation (SAMSEG) on T1w images in order to calculate a superior intracranial volume.</p>"},{"location":"projects/ongoing/freesurfer7/#pulling-the-docker-image","title":"Pulling the Docker image","text":"<p>You need to download the container image that will run the subsegmentations. Use the following Apptainer command to pull the image from Docker Hub:</p> <pre><code>apptainer build freesurfer_subseg_1.0.sif docker://nichyconsortium/freesurfer_subseg:1.0\n</code></pre> <p>Make sure the resulting image file is placed in the container directory referenced in your global config file.</p>"},{"location":"projects/ongoing/freesurfer7/#getting-the-nipoppy-pipeline-specification-files-for-this-pipeline","title":"Getting the Nipoppy pipeline specification files for this pipeline","text":"<p>To get the Nipoppy specification files for the subsegmentation container, run:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 15877956\n</code></pre> <p>Read more about this step here.</p> <p>Note: If you have multiple T1w images per subject per session, the container will throw an error. In this case, you will need to open the invocation file under <code>&lt;dataset_root&gt;/pipelines/processing/freesurfer_subseg-1.0/</code> and specify the name of the desired T1w image for SAMSEG in the following way:</p> <pre><code>\"t1_image_path\": \"[[NIPOPPY_BIDS_PARTICIPANT_ID]]_[[NIPOPPY_BIDS_SESSION_ID]]_&lt;edit-me&gt;_T1w.nii.gz\"\n</code></pre>"},{"location":"projects/ongoing/freesurfer7/#change-your-global-config-file","title":"Change your global config file","text":"<p>Open the global config file and add the path to your freesurfer license file under the freesurfer_subseg pipeline, just like you did for the fMRIPrep pipeline:</p> <pre><code>\"PIPELINE_VARIABLES\": {\n  \"BIDSIFICATION\": {},\n  \"PROCESSING\": {\n    \"fmriprep\": {\n      \"24.1.1\": {\n        \"FREESURFER_LICENSE_FILE\": \"path/to/license/file/license.txt\",\n        \"TEMPLATEFLOW_HOME\": \"path/to/templateflow/\"\n      }\n    },\n    \"freesurfer_subseg\": {\n      \"1.0\": {\n        \"FREESURFER_LICENSE_FILE\": \"path/to/license/file/license.txt\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"projects/ongoing/freesurfer7/#final-check","title":"Final check","text":"<p>Before trying to run the pipeline, confirm that the pipeline is recognized by running <code>nipoppy pipeline list</code>. This will print a list of the available pipelines.</p>"},{"location":"projects/ongoing/freesurfer7/#running-the-pipeline","title":"Running the pipeline","text":"<p>To run the subsegmentation pipeline, use the following command:</p> <pre><code>nipoppy process --pipeline freesurfer_subseg --pipeline-version 1.0 --dataset &lt;dataset_root&gt;\n</code></pre>"},{"location":"projects/ongoing/freesurfer7/#tracking-pipeline-output","title":"Tracking pipeline output","text":"<p>Use the <code>nipoppy track-processing</code> command to check which participants/sessions have complete output:</p> <pre><code>nipoppy track-processing --pipeline freesurfer_subseg --dataset &lt;dataset_root&gt;\n</code></pre> <p>This helps you confirm whether the pipeline ran successfully across your dataset (again, check <code>processing_status.tsv</code> under the <code>derivatives</code> folder).</p>"},{"location":"projects/ongoing/freesurfer7/#extracting-pipeline-output","title":"Extracting pipeline output","text":"<p>The pipeline for extraction of data from the subsegmentation is under construction. Stay tuned for updates! You can already extract data from the standard FreeSurfer 7 segementation (see here) and continue with running the fsqc toolbox as described below.</p>"},{"location":"projects/ongoing/freesurfer7/#quality-assessment-part-1-running-the-fs-qc-toolbox","title":"Quality Assessment part 1: Running the FS-QC toolbox","text":"<p>Congratulations, you made it to the quality assessment! For this purpose, we will use FreeSurfer Quality Control (FS-QC) toolbox. The FS-QC toolbox takes existing FreeSurfer (or FastSurfer) output and computes a set of quality control metrics. These will be reported in a summary table and/or .html page with screenshots to allow for visual inspection of the segmentations.</p>"},{"location":"projects/ongoing/freesurfer7/#pulling-the-docker-image_1","title":"Pulling the Docker image","text":"<p>You need to download the container image that will run the freesurfer quality control pipeline. Use the following command to pull the image from Docker Hub:</p> <pre><code>apptainer build fsqc_2.1.4.sif docker://deepmi/fsqcdocker:2.1.4\n</code></pre> <p>Make sure the resulting image file is placed in the container directory referenced in your global Nipoppy configuration.</p>"},{"location":"projects/ongoing/freesurfer7/#getting-the-nipoppy-pipeline-specification-files-for-this-pipeline_1","title":"Getting the Nipoppy pipeline specification files for this pipeline","text":"<p>To get the Nipoppy specification files for the FS-QC container, run:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 17100133\n</code></pre> <p>Read more about this step here.</p>"},{"location":"projects/ongoing/freesurfer7/#change-your-global-config-file_1","title":"Change your global config file","text":"<p>Open the global config file and add the correct freesurfer version (7.3.2) under the fsqc pipeline.</p>"},{"location":"projects/ongoing/freesurfer7/#final-check_1","title":"Final check","text":"<p>Before trying to run the pipeline, confirm that the pipeline is recognized by running <code>nipoppy pipeline list</code>. This will print a list of the available pipelines.</p>"},{"location":"projects/ongoing/freesurfer7/#running-the-pipeline_1","title":"Running the pipeline","text":"<p>To run the subsegmentation pipeline, use the following command:</p> <pre><code>nipoppy process --pipeline fsqc --pipeline-version 2.1.4 --pipeline-step process --dataset &lt;dataset_root&gt;\n</code></pre>"},{"location":"projects/ongoing/freesurfer7/#expected-fs-qc-output","title":"Expected FS-QC output","text":"<p>After running the command, you will find all results inside the derivatives folder. The output will include:</p> <ul> <li> <p>Several folders, most of them corresponding to the flags used in the command, such as: <code>screenshots</code>, <code>surfaces</code>, <code>skullstrip</code>, <code>hypothalamus</code>, <code>hippocampus</code>, and also, <code>status</code>, <code>metrics</code></p> </li> <li> <p>A CSV file (<code>fsqc-results.csv</code>) summarizing quantitative quality control metrics for all subjects.</p> </li> <li> <p>A main HTML summary file (<code>fsqc-results.html</code>) that aggregates all subject screenshots for easy visual inspection.</p> </li> </ul> <p>You can verify that images were created for all subjects by running</p> <pre><code>nipoppy track-processing --pipeline fsqc --pipeline-step process-tracking --dataset &lt;dataset_root&gt;\n</code></pre> <p>and checking <code>processing_status.tsv</code> under the <code>derivatives</code> folder.</p>"},{"location":"projects/ongoing/freesurfer7/#important-notes-for-viewing-and-copying-files","title":"Important notes for viewing and copying files:","text":""},{"location":"projects/ongoing/freesurfer7/#locally","title":"Locally","text":"<ul> <li> <p>We strongly recommend downloading the entire output folder locally before opening the HTML file. Opening the HTML on a server or network drive is often slow and may cause images not to load properly.</p> </li> <li> <p>When copying files, make sure to include all generated folders (such as <code>screenshots</code>, <code>surfaces</code>, etc.) along with the <code>fsqc-results.html</code> file. These folders contain the images referenced in the HTML and are essential for proper display.</p> </li> </ul>"},{"location":"projects/ongoing/freesurfer7/#on-the-server","title":"On the server","text":"<ul> <li>If you have not experienced such issues before and prefer to work directly on your server, you can instead open the HTML file in your available browser (for example: <code>firefox fsqc-results.html</code>).</li> </ul>"},{"location":"projects/ongoing/freesurfer7/#final-check_2","title":"Final check","text":"<ul> <li>When opening the <code>fsqc-results.html</code> file:  </li> <li>Scroll through the subjects to confirm all images load and no data is missing.  </li> <li>Click on any image to zoom in, or right-click and choose \u201cOpen in new tab\u201d and inspect details more closely.</li> </ul>"},{"location":"projects/ongoing/freesurfer7/#quality-assessment-part-2-performing-a-visual-quality-assessment","title":"Quality Assessment part 2: Performing a visual quality assessment","text":"<p>Quality checking is essential to make sure the output that you have produced is accurate and reliable. Even small errors or artifacts in images can lead to big mistakes in analysis and interpretation, so careful checks help us to verify whether we can savely include a certain region of interest or participant in our analysis. For the FreeSurfer output, we will follow standardized ENIGMA instructions on how to decide on the quality of the cortical and subcortical segmentations. At this stage, visual quality assessment of the subsegmentations (e.g., thalamic or hippocampal nuclei) is not required, as there are no established protocols yet and the process would be highly time-consuming; statistical checks (e.g., outlier detection) can be used instead. This may be followed up at a later stage, once there is a project that specifically focuses on these outcomes and the necessary anatomical expertise is available to develop a dedicated quality control manual.</p> <p>You can find the updated ENIGMA-PD QC instructions for visual inspection here.</p>"},{"location":"projects/ongoing/freesurfer7/#data-sharing","title":"Data sharing","text":"<p>After completing all of the above steps, you're ready to share your derived data with the ENIGMA-PD core team. Please:</p> <ul> <li>Review the .tsv and Excel spreadsheets for completeness, ensuring all participants are included, there are no missing or unexpected data points, and quality assessment scores have been assigned to each ROI and participant.</li> <li>Confirm whether you are authorized to share the quality check .png files. These will be used, along with your quality assessment scores, to help train automated machine learning models for ENIGMA's quality checking pipelines, to eliminate the need for manual checking in the future.</li> </ul> <p>Once these checks are complete, email enigma-pd@amsterdamumc.nl to receive a personalized and secure link to a SURFdrive folder where you can temporarily upload the .csv files and, if applicable, the QA .png files. If your site has another preferred method for sharing data, please let us know, and we will try to accommodate it. We will then move the files to our central storage on the LONI server hosted by USC.</p>"},{"location":"projects/ongoing/imaging_genetics/","title":"Imaging Genetics project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/ongoing/mspm/","title":"Multiple Symptom Progression Modelling project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/ongoing/neuropsych/","title":"Neuropsychiatry project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/ongoing/normative_modelling/","title":"Normative modelling (fMRI) project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/ongoing/overview/","title":"ENIGMA-PD ongoing projects showcase","text":"<ul> <li> <p> Update to FreeSurfer 7</p> </li> <li> <p> Cognitive reserve (fMRI)</p> </li> <li> <p> White Matter Lesions</p> </li> <li> <p> Multiple Symptom Progression Modelling</p> </li> <li> <p> Neuropsychiatry</p> </li> <li> <p> Spinal Cord Morphometry</p> </li> <li> <p> Imaging-Genetics</p> </li> <li> <p> Normative Modelling (fMRI)</p> </li> </ul>"},{"location":"projects/ongoing/spinal_cord/","title":"Spinal Cord project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"projects/ongoing/wml/","title":"White Matter Lesion project","text":"<p>This page is under construction and will soon be filled with exciting details about this project.</p>"},{"location":"resources/overview/","title":"Useful resources for ENIGMA-PD projects","text":"<ul> <li> <p> Why do BIDSification</p> </li> <li> <p> What is Templateflow</p> </li> <li> <p> Using containers</p> </li> <li> <p> Using pipeline configs</p> </li> </ul>"},{"location":"resources/how_to_guides/BIDS_info/","title":"BIDS info","text":""},{"location":"resources/how_to_guides/BIDS_info/#why-do-bidsification","title":"Why do BIDSification?","text":"<p>Before starting the analysis, organizing your data is essential \u2014 it will benefit this analysis and streamline any follow-up ENIGMA-PD work. We know it can be challenging, but we\u2019re here to support you. The Brain Imaging Data Structure (BIDS) format is a standardized format for organizing and labeling neuroimaging data to ensure consistency and make data easily shareable and analyzable across studies. Although we\u2019re focusing on T1-weighted images for this analysis, organizing available diffusion-weighted or functional MRI data in BIDS will make future analyses easier.</p> <p>Here are the core principles for organizing your neuroimaging data in BIDS format: - Use consistent file and folder names - Separate modalities - Include metadata files - Validate the structure</p> <p>Resources from the BIDS community offer guidance on organizing your data, and BIDS converters can help automate this process, saving time and reducing manual errors. We recommend using Dcm2Bids (for DICOM's) and BIDScoin (for NIfTI's). - BIDS documentation - Recommended converter; BIDScoin - BIDS tutorials</p>"},{"location":"resources/how_to_guides/Container_platforms/","title":"Container platforms","text":""},{"location":"resources/how_to_guides/Container_platforms/#installing-containers","title":"Installing containers","text":"<p>We will be using containerized pipelines for running FreeSurfer 7 segmentation, subsegmentation and the quality control script (and potentially BIDSification). Pipeline containers are self-contained software environments that package all the tools, dependencies, and code needed to run each step of a data analysis pipeline reproducibly and consistently across systems. To download and run containers, you need a container platform, either Apptainer/Singularity or Docker. We strongly suggest Apptainer/Singularity, which is fully supported by Nipoppy. Docker can be used if you have admin rights to the computer/server you are using, or you work on something other than a Linux system (like a Mac). Using Nipoppy with Docker is possible though will likely require help -- reach out to us on our Discord channel and we would be happy to chat!</p> <p>You may already have apptainer/singularity installed on your machine. You can try this by simply running <code>apptainer</code> or <code>singularity</code> in your command line and see if it throws an error. Sometimes you will need to load it to your environment, for example by running <code>module load apptainer</code>. If you don't have a container platform installed, you can find how to do this below.</p>"},{"location":"resources/how_to_guides/Container_platforms/#installation","title":"Installation","text":"<ul> <li>Install Apptainer</li> <li>Install Docker</li> </ul> <p>Once you have a container platform installed, you can start building containers in the following way. For apptainer, run:</p> <pre><code>apptainer build &lt;pipeline&gt;_&lt;version&gt;.sif \\\n                    docker://&lt;repository&gt;/&lt;pipeline&gt;:&lt;version&gt;\n</code></pre> <p>For docker, run:</p> <pre><code>docker pull &lt;repository&gt;/&lt;pipeline&gt;:&lt;version&gt;\n</code></pre> <p>Nipoppy encourages the use of a common directory for storing container images, which can be shared across datasets/individuals. This directory can be anywhere on a system. </p> <p>Note: in the global config file, <code>&lt;NIPOPPY_DPATH_CONTAINERS&gt;</code> should be replaced by the actual path to that directory. We encourage you to create a symlink from the <code>&lt;DATASET_ROOT&gt;/containers</code> directory inside the Nipoppy dataset to the shared container store location, as this would allow anyone looking at the dataset easily find the containers. In that case this substitution entry can be deleted, since by default Nipoppy will use <code>&lt;DATASET_ROOT&gt;/containers</code>.</p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/","title":"ENIGMA-PD Visual Quality Control Instructions","text":"<p>Welcome to the ENIGMA-PD FreeSurfer Visual Quality Control Manual Last updated: August 2025</p> <p>This page outlines the recommended approach to visually inspect and rate FreeSurfer segmentations as part of the ENIGMA-PD project. We will assess the cortical and subcortical areas only, not the subsegmentations. </p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#step-by-step-instructions-for-visual-inspection","title":"Step-by-step instructions for visual inspection","text":""},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#1-download-the-template-spreadsheets","title":"1. Download the template spreadsheets","text":"<ul> <li>Download the Cortical QC template</li> <li>Download the Subcortical QC template</li> </ul> <p>These templates should be filled in manually. The only changes to be made to these templates are 1) adding all subjects from your dataset in the first column (you can copy over file names from your nipoppy manifest file), and 2) changing quality control scores from <code>\"pass\"</code> to <code>\"fail\"</code> if needed. The cortical template contains two tabs: the first tab is used to record the visual inspection scores, while the second tab provides additional context on common quality control issues observed in ENIGMA projects.  You do not need to review or complete the second tab \u2014 it is included to stay consistent with the standard ENIGMA consortium template. The subcortical template consists of one tab, with the selected subcortical areas for visual inspection.</p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#2-learn-about-the-scoring","title":"2. Learn about the scoring","text":"<p>In the template spreadsheet, all regions are by default marked as a <code>\"pass\"</code>. Raters are asked to provide a score for each region: either <code>\"pass\"</code> or <code>\"fail\"</code>, no other values should be used.</p> <p>Be conservative when failing: Use the <code>\"fail\"</code> label only when there are obvious, serious issues that would make the regional estimates unreliable or unusable.  Small flaws or mild asymmetries are typically not enough to justify a fail. </p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#types-of-scores","title":"Types of scores","text":"<p>For the cortical quality control, you will complete several types of scores: an overall score for internal and external QC, and specific scores for each region, assessed separately for the left and right hemispheres. You may optionally add comments or a QC_code (as defined in the second tab of the spreadsheet), but these are not required for the ENIGMA-PD quality assessment.</p> <p>For the subcortical quality control, you will provide specific scores for each region, again assessed separately for the left and right hemispheres. In addition, there is an overarching column <code>Overall_subcortical_QC</code>. This can be set to <code>fail</code> when all individual regions fail (please still put <code>fail</code> for each column). If <code>Overall_subcortical_QC</code> is set to fail, the subject will be excluded from the subcortical analysis.</p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#3-familiarize-yourself-with-enigma-quality-control-standards","title":"3. Familiarize yourself with ENIGMA quality control standards","text":"<p>Before starting, review the ENIGMA quality control instructions, including common segmentation errors and regions that are more prone to segmentation failure. You can find the ENIGMA manuals, adapted for the PD group below: - ENIGMA-PD Cortical Quality Control Manual   - Version of the cortical quiz slides including the answers to the quiz - ENIGMA-PD Subcortical Quality Control Manual</p> <p>We recommend not focusing too heavily on the manuals. Though they do provide some useful examples, hands-on practice is key to learning quality control, and the quality of someone\u2019s visual assessment improves primarily through experience.</p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#4-check-out-the-fsqc-generated-html-page-with-screenshots","title":"4. Check out the fsqc-generated html page with screenshots","text":"<p>Open the <code>fsqc-results.html</code> in your browser. This page shows several different images for each subject of your dataset: - Screenshots: For internal quality control of the cortical areas and to inspect the subcortical areas - Skullstrip: To confirm whether skullstripping was successful. If skullstripping failed, regions that are not covered by the extracted brain mask (but should have been) and possibly those near the edges of the brain will fail quality control (for example, the cerebellum).  - Surfaces: For external quality control of the cortical areas - Hypothalamus: For quality control of the hypothalamus subsegmentations - Hippocampus: For quality control of the hippocampus and amygdala subsegmentations</p> <p>For a walkthrough of how these look in practice, check out the FSQC tour.</p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#5-cortical-quality-control","title":"5. Cortical Quality Control","text":""},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#warm-up-dynamically-check-a-few-subjects-across-all-regions","title":"Warm-up: dynamically check a few subjects across all regions","text":"<p>Start by quickly scrolling through around 5\u201310 subjects to get a sense of the typical variability in cortical segmentations. This dynamic review helps you become familiar with how correctly segmented regions usually appear and what kinds of errors to expect.</p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#for-the-full-dataset-go-per-region","title":"For the full dataset, go per region","text":"<p>Most raters prefer evaluating one cortical region at a time across all subjects. This helps with consistency and speeds up spotting systematic issues. As you go, flag any doubtful cases, either to revisit later or to share with the ENIGMA core team for second opinion.</p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#6-subcortical-quality-control","title":"6. Subcortical Quality Control","text":"<p>After the cortical regions, the subcortical quality control is a piece of cake. Subcortical regions are located close together and can usually be assessed in a single glance (in contrast to the region-by-region approach of the cortical segmentations). Segmentation errors are uncommon, and most regions should pass. Approve unless there are clear, severe distortions, which often affect multiple or all neighboring subcortical regions rather than just one.</p>"},{"location":"resources/how_to_guides/ENIGMA-PD_visual_QC_instructions/#things-to-keep-in-mind","title":"Things to Keep in Mind","text":"<ul> <li>Be lenient: Only exclude segmentations with clear, severe errors that would lead to invalid regional estimates.  </li> <li>As you review more subjects, it becomes easier to recognize these major failures quickly.  </li> <li>When in doubt, keep the data, borderline cases are usually acceptable for analysis.</li> </ul>"},{"location":"resources/how_to_guides/Templateflow_info/","title":"Templateflow info","text":""},{"location":"resources/how_to_guides/Templateflow_info/#clarifications-about-templateflow","title":"Clarifications about Templateflow","text":"<p>Templateflow is a library of neuroimaging templates (e.g. <code>MNI152NLin2009cAsym</code>) used by several popular processing pipelines, including fMRIPrep (which we are using to run FreeSurfer 7) and MRIQC.</p> <p>By default the templates are stored in <code>~/.templateflow</code>, but in general it is a good idea to store them somewhere more central/visible, so that the same templates can be used by different people in a research group. Another reason to specify another path is that the home directory often has limited storage on some servers.   - In the Nipoppy global config file, <code>&lt;PATH_TO_TEMPLATEFLOW_DIRECTORY&gt;</code> should be replaced by the path to an empty directory, possibly in a similar location as (parallel to) the container store directory.</p> <p>The first time fMRIPrep is run, it will attempt to download templates to the Templateflow directory, which will require the computer to be connected to the internet. If you are running fMRIPRep on a cluster where compute nodes do not have access to the Internet, see here and feel free to reach out to us for help.</p>"},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/","title":"getting ENIGMA PD pipeline config files","text":""},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#getting-the-nipoppy-pipeline-specification-files-for-a-new-pipeline","title":"Getting the Nipoppy pipeline specification files for a new pipeline","text":"<p>To run pipeline containers within Nipoppy, you need to download the required pipeline configuration files from Zenodo. Together, these files allow Nipoppy to recognize, configure, run, and monitor the custom container image as part of its structured processing framework. You will need the following:</p> <ul> <li><code>descriptor.json</code></li> <li><code>invocation.json</code></li> <li><code>config.json</code></li> <li><code>tracker_config.json</code></li> </ul> <p>A quick way to download these four files is by running: <code>nipoppy pipeline install --dataset &lt;DATASET_ROOT&gt; &lt;ZENODO_ID&gt;</code></p> <p>Please read more instructions about adding a pipeline to a dataset on the nipoppy documentation page.</p> <p>Note: Every time a new pipeline is installed, you will need to change some paths in the global config file, depending on the pipeline.</p>"},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#examples","title":"Examples","text":""},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#fmriprep","title":"fmriprep","text":"<p>Latest pipeline version: <code>fmriprep-24.1.1</code></p> <p>Zenodo id: 15427833</p>"},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#freesurfer_subseg","title":"freesurfer_subseg","text":"<p>Latest pipeline version: <code>freesurfer_subseg-1.0</code></p> <p>Zenodo id: 15877956</p>"},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#fsqc","title":"fsqc","text":"<p>Latest pipeline version: <code>fsqc-2.1.1</code></p> <p>Zenodo id: 16810923</p>"},{"location":"working_group/core_team/","title":"ENIGMA-PD Core Team","text":"<p>Meet the people behind ENIGMA-PD!</p> <ul> <li> Ysbrand van der Werf   Amsterdam UMC, The Netherlands</li> <li> Max Laansma   Amsterdam UMC, The Netherlands</li> <li> Conor Owens-Walton   University of Southern California, USA</li> <li> Eva van Heese   Amsterdam UMC, The Netherlands</li> <li> Paul Thompson   University of Southern California, USA</li> <li> Neda Jahanshad   University of Southern California, USA</li> <li> Emile d'Angremont   Amsterdam UMC, The Netherlands</li> </ul>"},{"location":"working_group/new_sites/","title":"Useful information for new sites","text":"<p>Interested in joining ENIGMA-PD? Send us an email at enigma-pd@amsterdamumc.nl!</p>"},{"location":"working_group/sites/","title":"Global sites in ENIGMA-PD","text":""},{"location":"working_group/sites/#site-locations","title":"Site Locations","text":"<ul> <li>Amsterdam</li> <li>Bern</li> <li>Bonn</li> <li>Brisbane</li> <li>Brno</li> <li>Brown</li> <li>Christchurch</li> <li>Cologne</li> <li>Graz</li> <li>Groningen</li> <li>Liege</li> <li>Manchester</li> <li>McGill</li> <li>Milan</li> <li>Neurocon</li> <li>Nijmegen</li> <li>Oxford</li> <li>Rome</li> <li>Seoul</li> <li>Sevilla</li> <li>Singapore</li> <li>Stanford</li> <li>Stellenbosch</li> <li>Taipai</li> <li>San Fransisco</li> <li>Campinas</li> <li>Philadelphia</li> <li>Charlottesville</li> </ul>"}]}